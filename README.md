# ML Assignment â€“ Probabilistic Models, Decision Trees & Random Forests

This repository contains complete from-scratch implementations of:

- Gaussian Generative Classifier (LDA-style)
- Gaussian Naive Bayes
- Decision Tree Classifier for continuous features
- Random Forest using custom decision trees

The project follows a full ML pipeline: dataset preparation, stratified splitting,
hyperparameter tuning, evaluation, metrics, visualization, and model comparison.



---



## ğŸ” Implemented Models

### **1. Gaussian Generative Classifier**
- Estimates class priors, means, shared covariance
- Uses regularized Î£ + Î»I
- Tuned over Î» âˆˆ {1eâˆ’4, 1eâˆ’3, 1eâˆ’2, 1eâˆ’1}

### **2. Naive Bayes (Categorical)**
- Laplace smoothing Î± âˆˆ [0.1, 5]
- Comparisons with sklearnâ€™s MultinomialNB
- Full probability-table implementation

### **3. Decision Tree (from scratch)**
- Continuous feature splits
- Entropy & Information Gain
- Hyperparameters:
  - max_depth âˆˆ {2,4,6,8,10}
  - min_samples_split âˆˆ {2,5,10}
- Feature importance via accumulated information gain

### **4. Random Forest (Bonus)**
- Bootstrap sampling
- Random feature subsets
- Majority voting
- Hyperparameters:
  - T âˆˆ {5,10,30,50}
  - max_features âˆˆ {sqrt(d), d/2}

---

## ğŸ“Š Evaluation

Each model includes:

- Accuracy, Precision, Recall, F1
- Confusion matrix
- Cross-model comparison
- Biasâ€“variance analysis (Tree vs Forest)

---

## ğŸ§  Why This Project is Interesting

This project demonstrates:

- Complete ML model implementations **without sklearn**  
- Understanding of entropy, information gain, and tree construction  
- Ensemble learning and variance reduction  
- Real-world datasets (Digits, Adult, Breast Cancer)

This builds skills in:
- Mathematical modeling  
- Core ML algorithms    
- Experimental analysis  

